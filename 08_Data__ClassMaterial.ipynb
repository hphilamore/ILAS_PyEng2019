{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 08 Data  \n",
    "## CLASS MATERIAL\n",
    "\n",
    "<br> <a href='#InstallPandas'>1. InstallPandas</a>\n",
    "<br> <a href='#PandasDataStructures'>2. Pandas Data Structures</a> \n",
    "<br> <a href='#DataIndexingSelection'>3. Data Indexing and Selection</a> \n",
    "<br> <a href='#PerformingOperationsDataPandas'>4. Performing Operations on Data in Pandas</a> \n",
    "<br><a href='#DataCleaning'>5. Data Cleaning</a>\n",
    "<br><a href='#CombiningDatasets'>6. Combining Datasets</a>\n",
    "<br><a href='#AggregationGrouping'>7. Summarising Data with Aggregation and Grouping</a>\n",
    "<br><a href='#StringData'>8. Working with `String` Data</a>\n",
    "<br><a href='#TimeSeries'>9. Working with Time Series</a>\n",
    "<br><a href='#ReviewExercises'>10. Review Exercises</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Download the new class notes.\n",
    "__Navigate to the directory where your files are stored.__\n",
    "\n",
    "__Update the course notes by downloading the changes__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "##### Windows\n",
    "Search for __Git Bash__ in the programs menu.\n",
    "\n",
    "Select __Git Bash__, a terminal will open.\n",
    "\n",
    "Use `cd` to navigate to *inside* the __ILAS_PyEng2019__ repository you downloaded. \n",
    "\n",
    "Run the command:\n",
    ">`./automerge`\n",
    "\n",
    "\n",
    "\n",
    "##### Mac\n",
    "Open a terminal. \n",
    "\n",
    "Use `cd` to navigate to *inside* the __ILAS_PyEng2019__ repository you downloaded. \n",
    "\n",
    "Run the command:\n",
    ">`sudo ./automerge`\n",
    "\n",
    "Enter your password when prompted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This week we begin the __Applications of Programming__ part of the course. \n",
    "\n",
    "In this part of the course, we will explore some uses of programming in which you can apply the fundamental techniques we have studied so far and your specialism as engineers. \n",
    "\n",
    "The first topic we will cover is handling of data, specifically large and unstructured data sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Data Science__ :  \n",
    "A field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data.\n",
    "\n",
    "It employs techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, and informatics. \n",
    "\n",
    "Data sets are modelled and curated to find patterns and make predictions about the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Machine Learning__ :  \n",
    "An important tool used with Data Science is machine learning. \n",
    "\n",
    "In Machine learning, algorithms acquire the knowledge or skill through experience. \n",
    "\n",
    "Therefore, Machine learning relies on big data sets to identify patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Artificial Intelligence (AI):__\n",
    "<br>AI is the study of enabling machines to make decisions independently without the need for human interference. \n",
    "\n",
    "Therefore AI tends to be used in situations where adapting to new scenarios are important.\n",
    "<br>As this often involves acquiring knowledge and learning to apply it, Machine Learning is a widely used approach for AI. \n",
    "\n",
    "AI has broad application ranging from robotics to text analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/machine_learning_AI.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In Data Science, Machine Learning and AI, typical problems involve large amounts of __unstructured data__.\n",
    "\n",
    "__Unstructured data__ \n",
    "Information that is not organised in a pre-defined manner (e.g. does not fit nicely into a numpy array). \n",
    "- text-heavy\n",
    "- mixed data types (dates, numbers, text info ...)  \n",
    "- missing data (transmitted data packet, sensor data)\n",
    "- noise (sensor data, experimental results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lesson Goal\n",
    "\n",
    "- Data strutures for data science : Pandas `DataFrame` and `Series` \n",
    "- Data cleaning: remove missing values, filtering rows or columns by some criteria\n",
    "- Calculate statistics and analytics \n",
    "    - e.g. average, median, max, min of each column\n",
    "    - does column A correlate with column B?\n",
    "    - distribution of data in column C\n",
    "\n",
    "- Data visualization \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fundamental programming concepts\n",
    " \n",
    "Using python Pandas, a powerful python tool for data handling. \n",
    "\n",
    "Pandas is built on top of NumPy and enables fast analysis, data cleaning and preparation. \n",
    "\n",
    "We can think of Pandas as Python’s version of Microsoft’s Excel.\n",
    "\n",
    "Unlike Excel, Pandas works well with data from a wide variety of diverse sources such as; Excel sheet, csv file, or even a webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas\n",
    "<a id='Pandas'></a>\n",
    "Pandas stands for “Python Data Analysis Library”.\n",
    "\n",
    "<img src=\"img/panda.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='InstallPandas'></a>\n",
    "# 1. Install Pandas\n",
    "\n",
    "\n",
    "\n",
    "##### Windows \n",
    "\n",
    "1. Open the Anaconda Prompt from the terminal.\n",
    "<p align=\"center\">\n",
    "  <img src=\"img/anaconda_prompt.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "</p>\n",
    "\n",
    "1. The window that opens will look like the command line. In the window type the following code then press 'Enter':\n",
    ">`conda install -c anaconda pip`\n",
    "\n",
    "1. When the installation completes type the following code then press 'Enter':\n",
    ">`pip install pandas`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Mac\n",
    "\n",
    "1. Open a terminal. \n",
    "\n",
    "1. Type the following code then press 'Enter':\n",
    ">`conda install -c anaconda pip`\n",
    "\n",
    "1. When the installation completes type the following code then press 'Enter':\n",
    ">`pip install pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To check the installation has worked type try importing pandas in Spyder or Jupyter notebook and run the code. If no error is generated you have installed pandas successfully. \n",
    "\n",
    "Just as we generally import Numpy as ``np``, we will import Pandas as ``pd``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will also use numpy and matplotlib in this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Documentation\n",
    "\n",
    "In Jupyter Notebook you the can quickly view the contents of a package (by using the tab-completion feature) as well as the documentation of various functions (using the ``?`` character). \n",
    "\n",
    "For example, to display all the contents of the pandas namespace, you can type\n",
    "\n",
    "```ipython\n",
    "In [3]: pd.<TAB>\n",
    "```\n",
    "\n",
    "And to display Pandas's built-in documentation, you can use this:\n",
    "\n",
    "```ipython\n",
    "In [4]: pd?\n",
    "```\n",
    "\n",
    "More detailed documentation, along with tutorials and other resources, can be found at http://pandas.pydata.org/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='PandasDataStructures'></a>\n",
    "# 2. Pandas Data Structures\n",
    "\n",
    "<br> <a href='#Series'>2.1 `Series`</a>\n",
    "<br> <a href='#ConstructingSeriesObjects'>2.2 Constructing `Series` Objects</a>\n",
    "<br> <a href='#DataFrame'>2.3 `DataFrame`</a>\n",
    "<br> <a href='#ConstructingDataFrame'>2.4 Constructing a `DataFrame`</a>\n",
    "<br> <a href='#ConstructingDataFrameImportingData'>2.5 Constructing a `DataFrame by Importing Data`</a>\n",
    "\n",
    "\n",
    "We will first look at the data structures provided by the Pandas library.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The numPy `array` data structure is useful for clean, well-organized data typically seen in numerical computing tasks.\n",
    "\n",
    "It is limited when more flexibility is needed:\n",
    " - attaching labels to data\n",
    " - working with missing data\n",
    " - grouping data \n",
    "\n",
    "``DataFrame``s are essentially multidimensional arrays with row and column labels\n",
    "\n",
    "They often contain heterogeneous types and/or missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='Series'></a>\n",
    "## 2.1 `Series`\n",
    "\n",
    "A Pandas ``Series`` is a one-dimensional array of indexed data.\n",
    "\n",
    "It can be created from a list or array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.25\n",
       "1    0.50\n",
       "2    0.75\n",
       "3    1.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Like with a NumPy array, data can be accessed with square-bracket *implicitly defined integer* indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.50\n",
       "2    0.75\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]\n",
    "\n",
    "data[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ``Series`` as generalized NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or, unlike a numpy array, data can be accessed with square-bracket *explicitly defined* index associated with the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strings as indices\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=['a', 'b', 'c', 'd'])\n",
    "data\n",
    "\n",
    "data['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.25\n",
       "5    0.50\n",
       "3    0.75\n",
       "7    1.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-contiguous or non-sequential indices\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=[2, 5, 3, 7])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='ConstructingSeriesObjects'></a>\n",
    "## 2.2 Constructing Series Objects\n",
    "\n",
    "\n",
    "\n",
    "A Pandas ``Series`` constructed from scratch; always has the following format:\n",
    "\n",
    "```python\n",
    ">>> pd.Series(data, index=index)\n",
    "```\n",
    "\n",
    "``index`` is an optional argument (default : integer array)\n",
    "\n",
    "``data`` can be given in various ways e.g.  list or NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    4\n",
      "2    6\n",
      "dtype: int64\n",
      "\n",
      "100    5\n",
      "200    5\n",
      "300    5\n",
      "dtype: int64\n",
      "\n",
      "2    a\n",
      "1    b\n",
      "3    c\n",
      "dtype: object\n",
      "\n",
      "3    c\n",
      "2    a\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series([2, 4, 6]), \n",
    "      end='\\n\\n')\n",
    "\n",
    "print(pd.Series(5, index=[100, 200, 300]), # data is repeated scalar\n",
    "      end='\\n\\n') \n",
    "\n",
    "print(pd.Series({2:'a', 1:'b', 3:'c'}), # data is dictionary (see Supplementary material)\n",
    "      end='\\n\\n') \n",
    "\n",
    "print(pd.Series({2:'a', 1:'b', 3:'c'}, index=[3, 2]), # Iindex is explicitly set\n",
    "      end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='DataFrame'></a>\n",
    "## 2.3 `DataFrame` \n",
    "\n",
    "`Series` :  behaves as a 1D array with user-specifiable row indices. \n",
    "\n",
    "`DataFrame` : behaves as a 2D array with both user-specifiable row indices *and* column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "2D array : ordered sequence of aligned one-dimensional columns.\n",
    "\n",
    "`DataFrame` :  sequence of `Series` objects with the same index order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example : Construct two series..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct two series\n",
    "area_dict = {'California': 423967, \n",
    "             'Texas': 695662, \n",
    "             'New York': 141297,\n",
    "             'Florida': 170312, \n",
    "             'Illinois': 149995}\n",
    "\n",
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "\n",
    "population = pd.Series(population_dict)\n",
    "area = pd.Series(area_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Combine two series as data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>38332521</td>\n",
       "      <td>423967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>26448193</td>\n",
       "      <td>695662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>19651127</td>\n",
       "      <td>141297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>19552860</td>\n",
       "      <td>170312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>12882135</td>\n",
       "      <td>149995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            population    area\n",
       "California    38332521  423967\n",
       "Texas         26448193  695662\n",
       "New York      19651127  141297\n",
       "Florida       19552860  170312\n",
       "Illinois      12882135  149995"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = pd.DataFrame({'population': population,\n",
    "                       'area': area})\n",
    "\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Potential source of confusion:__\n",
    "<br>In a two-dimensional NumPy array called `data`, ``data[0]`` will return the first *row*. \n",
    "\n",
    "For a ``DataFrame`` called `data`, ``data['col0']`` will return the first *column*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.4 Constructing a `DataFrame`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ConstructingSeriesObjects\n",
    "\n",
    "A Pandas ``DataFrame`` can be constructed in a variety of ways; always with the following format:\n",
    "\n",
    "```python\n",
    ">>> pd.Series(data, columns=columns)\n",
    "```\n",
    "\n",
    "``columns`` is an optional argument (default : first value in each column)\n",
    "\n",
    "``data`` can be given in various ways ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### From a single `Series` object\n",
    "\n",
    "A ``DataFrame`` is a collection of ``Series`` objects, and a single-column ``DataFrame`` can be constructed from a single ``Series``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>38332521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>26448193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>19651127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>19552860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>12882135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            population\n",
       "California    38332521\n",
       "Texas         26448193\n",
       "New York      19651127\n",
       "Florida       19552860\n",
       "Illinois      12882135"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These two lines can be used interchangeably\n",
    "\n",
    "population_df = pd.DataFrame(population, columns=['population']) # Series, columns = series name\n",
    "\n",
    "population_df = pd.DataFrame({'population': population}) # Series name, series. dict structure\n",
    "\n",
    "population_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### From a dictionary of Series objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>38332521</td>\n",
       "      <td>423967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>26448193</td>\n",
       "      <td>695662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>19651127</td>\n",
       "      <td>141297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>19552860</td>\n",
       "      <td>170312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>12882135</td>\n",
       "      <td>149995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            population    area\n",
       "California    38332521  423967\n",
       "Texas         26448193  695662\n",
       "New York      19651127  141297\n",
       "Florida       19552860  170312\n",
       "Illinois      12882135  149995"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'population': population,\n",
    "              'area': area})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### From a python `dict` (dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keys</th>\n",
       "      <th>vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keys                vals\n",
       "0    A           [0, 0, 0]\n",
       "1    B        [0, 0, 0, 0]\n",
       "2    C     [0, 0, 0, 0, 0]\n",
       "3    D  [0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'keys':['A', 'B', 'C', 'D'],\n",
    "                   'vals':[[0,0,0],\n",
    "                         [0,0,0,0],\n",
    "                         [0,0,0,0,0],\n",
    "                         [0,0,0,0,0,0]]},\n",
    "                  \n",
    "                   columns=['keys', 'vals'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### From a list of dicts\n",
    "\n",
    "Any list of dictionaries can be made into a ``DataFrame``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a     b\n",
       "0  1     1\n",
       "1  2    10\n",
       "2  3  1000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [{'a': 1, 'b': 1},\n",
    "        {'a': 2, 'b': 10},\n",
    "        {'a': 3, 'b': 1000}]\n",
    "\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If some indices (keys) in the dictionary are missing, Pandas will fill them in with ``NaN`` (i.e., \"not a number\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a  b    c\n",
       "0  1.0  2  NaN\n",
       "1  NaN  3  4.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([{'a': 1, 'b': 2}, \n",
    "              {'b': 3, 'c': 4}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### From a two-dimensional NumPy array\n",
    "\n",
    "Given a two-dimensional array of data, we can create a ``DataFrame`` with any specified column and index names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foo</th>\n",
       "      <th>bar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.576998</td>\n",
       "      <td>0.328181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.128759</td>\n",
       "      <td>0.034142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.933142</td>\n",
       "      <td>0.019105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        foo       bar\n",
       "a  0.576998  0.328181\n",
       "b  0.128759  0.034142\n",
       "c  0.933142  0.019105"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.random.rand(3, 2),   # 3 x 2 array\n",
    "             columns=['foo', 'bar'], # column names\n",
    "             index=['a', 'b', 'c'])  # rows indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.5 Constructing a `DataFrame` by Importing Data\n",
    "\n",
    "\n",
    "\n",
    "Often we want to use data from an external source such as a website or exernal data file. \n",
    "\n",
    "Panda's IO tools (input-output tools) make it easy to import data from almost any data source. https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html\n",
    "\n",
    "The choice of function to use depends on the file format:\n",
    "\n",
    "Examples:\n",
    "\n",
    "`read_csv` : for delimited files including .txt files\n",
    "\n",
    "`read_json` : JavaScript Object Notation primarily used for transmitting data between a web application and a server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The function argument is the location of the file to import.\n",
    "\n",
    "This can be a file location on your computer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'sample_data/sample_student_data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-632c12eb9e47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_data/sample_student_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstudents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'sample_data/sample_student_data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "students = pd.read_csv('sample_data/sample_student_data.csv')\n",
    "students.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. or an online location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'  \n",
    "chipotle = pd.read_csv(url, sep = '\\t')  # tsv file (tab seperated) is specified when importing\n",
    "chipotle.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assigning Names to Unlabelled Data.\n",
    "<a id='AssigningNamesUnlabelledData'></a>\n",
    "Sometimes your data doesn't have column or row names.\n",
    "\n",
    "`pandas` will try to create them.\n",
    "\n",
    "`sample_data/noHeader_noIndex.csv` contains the data:\n",
    "\n",
    "```Python\n",
    "65.056,  1.053,  2.105,  3.158,  4.211\n",
    "74.452, 48.348, 68.733, 59.796, 54.123\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The first row is automatically used as the columns headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv('sample_data/noHeader_noIndex.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Therefore, if there are no headers, in the imported file, they should either be omitted..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('sample_data/noHeader_noIndex.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "... or assigned by the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"U\",\"V\",\"X\",\"Y\",\"Z\"]\n",
    "\n",
    "pd.read_csv('sample_data/noHeader_noIndex.csv', names=headers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note, this can also be used to *replace* existing column names on import as we will see later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Import Options\n",
    "<a id='ImportOptions'></a>\n",
    "The read_csv function has a large number of keyword arguments:\n",
    "http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.read_csv.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here are two examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`skiprows`: rows to omit\n",
    "\n",
    "`sample_data/sample_student_data.csv` has some unecessary information in row 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('sample_data/sample_student_data.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('sample_data/sample_student_data.csv', skiprows=[1]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`index_col`: the names in any column can be used as the index used to select a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOB as index\n",
    "pd.read_csv('sample_data/sample_student_data.csv', \n",
    "            skiprows = [1], \n",
    "            index_col = 2).head()\n",
    "\n",
    "# Student (JW- code) as index\n",
    "pd.read_csv('sample_data/sample_student_data.csv', \n",
    "            skiprows = [1], \n",
    "            index_col = 0).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='DataIndexingSelection'></a>\n",
    "# 3. Data Indexing and Selection\n",
    "\n",
    "<br> <a href='#DataSelectionSeries'>3.1 Data Selection in `Series`</a>\n",
    "<br> <a href='#SeriesIndexers'>3.2 `Series` Indexers: loc & iloc</a> \n",
    "<br> <a href='#DataSelectionDataFrame'>3.3 Data Selection in  `DataFrame`</a> \n",
    "<br> <a href='#DataFrameIndexers'>3.4  `DataFrame` Indexers: loc & iloc</a> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing (accessing individual elements by index) works a little differently than nother data structures. \n",
    "\n",
    "However, if we keep in mind how to access the elements of a numpy array, the process will hopefully seem logical. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='DataSelectionSeries'></a>\n",
    "## 3.1 Data Selection in `Series`\n",
    "\n",
    "\n",
    "\n",
    "A ``Series`` object acts in many ways like a 1D NumPy array (or a standard Python dictionary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implicit indexing\n",
    "data = np.array([0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "print(data)\n",
    "print(data[0])\n",
    "print(data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicint indexing\n",
    "import pandas as pd\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=['a', 'b', 'c', 'd'])\n",
    "print(data)\n",
    "print(data['a'])\n",
    "print(data['c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The same basic mechanisms of NumPy array-style item selection : \n",
    "- slicing\n",
    "- masking\n",
    "\n",
    "can be used. \n",
    "\n",
    "The only difference is that the indices may be *explicitly* defined.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# masking\n",
    "data[(data > 0.3) & (data < 0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# fancy indexing\n",
    "data[['a', 'c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# slicing by implicit integer index\n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# slicing by explicit (user-defined) index\n",
    "data['a':'c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Potential source of confusion:__\n",
    "\n",
    "When slicing with an explicit index (e.g. ``data['a':'c']``), the final index is *included* in the slice.\n",
    "\n",
    "When slicing with an implicit index (e.g. ``data[0:2]``), the final index is *excluded* from the slice.\n",
    "\n",
    "If a ``Series`` has an *explicit integer* index:\n",
    "- indexing operation e.g. ``data[1]`` will use the *explicit* \n",
    "- a slicing operation e.g. ``data[1:3]`` will automatically use the *implicit* array-style index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0], index=[1, 2, 3, 4])\n",
    "\n",
    "# explicit index when indexing\n",
    "print(data[1], end='\\n\\n')\n",
    "\n",
    "# implicit index when slicing\n",
    "print(data[1:3], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "<a id='SeriesIndexers'></a>\n",
    "## 3.2 `Series` Indexers: loc & iloc\n",
    "\n",
    "To get around the problem caused in the case of integer indexes, Pandas has special *indexers* that explicitly show which indexing scheme is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always references the explicit index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## iloc\n",
    "Always references the implicit Python array-style index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One principle of Python is that \"explicit is better than implicit.\"\n",
    "\n",
    "The explicit nature of ``loc`` and ``iloc`` make them very useful in maintaining clean and readable code and avoiding bugs due to mixed indexing/slicing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='DataSelectionDataFrame'></a>\n",
    "## 3.3 Data Selection in  `DataFrame`\n",
    "\n",
    "\n",
    "\n",
    "A ``DataFrame`` acts in many ways like:\n",
    "- a dictionary (see supplementary)\n",
    "- a 2D array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "area = pd.Series({'California': 423967, \n",
    "                  'Texas': 695662,\n",
    "                  'New York': 141297, \n",
    "                  'Florida': 170312,\n",
    "                  'Illinois': 149995})\n",
    "\n",
    "pop = pd.Series({'California': 38332521, \n",
    "                 'Texas': 26448193,\n",
    "                 'New York': 19651127, \n",
    "                 'Florida': 19552860,\n",
    "                 'Illinois': 12882135})\n",
    "\n",
    "data = pd.DataFrame({'area':area, 'pop':pop})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DataFrame as a dictionary\n",
    "\n",
    "The individual ``Series`` that make up the columns of the ``DataFrame`` can be accessed via dictionary-style indexing using the column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['area'] # dictionary style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.area # . shorthand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.area is data['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Shorthand e.g. `data.area`, does not work in some cases:\n",
    "- if the column names are not strings\n",
    "- if the column names conflict with methods of the ``DataFrame``<br>(e.g. the ``DataFrame`` has a ``pop()`` method. ``data.pop`` will run the method not the ``\"pop\"`` column)\n",
    "- column assignment <br>(i.e. use ``data['pop'] = z``, not ``data.pop = z``).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example : Editing a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pop is data['pop']\n",
    "\n",
    "data.pop = 3        # has no effect on DataFrame\n",
    "# data['pop'] = 3   # changes all values in pop column to 3\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example : Adding a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['density'] = data['pop'] / data['area']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DataFrame as two-dimensional array\n",
    "\n",
    "As mentioned previously, we can also view the ``DataFrame`` as an enhanced two-dimensional array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data structures with implicit indices may be indexed as numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.random.rand(3, 2))\n",
    "\n",
    "print(data, end='\\n\\n')\n",
    "\n",
    "print(data[1:2][0]) # rows 1 to 2, column 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For *explicitly indexed* of ``DataFrame`` objects, limited indexing is available.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.random.rand(3, 2),\n",
    "             columns=['foo', 'bar'],\n",
    "             index=['a', 'b', 'c'])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Access a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['foo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Access a row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.values[0] # row 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Access a region like with numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.values[::2, 0] # every other row, column 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Some more examples\n",
    "\n",
    "data = pd.DataFrame(np.random.rand(3, 2),\n",
    "             columns=['foo', 'bar'],\n",
    "             index=['a', 'b', 'c'])\n",
    "\n",
    "print(data, \n",
    "      end='\\n\\n')\n",
    "\n",
    "data['foo'] # column\n",
    "\n",
    "data.values[0] # row\n",
    "\n",
    "data[1:2]  # multiple rows\n",
    "\n",
    "data[1:2].foo # single column, multiple rows\n",
    "\n",
    "data[['foo']][:2] # single column, multiple rows\n",
    "\n",
    "data[['foo', 'bar']][1:3] # multiple columns, multiple rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These commands produce the same result : first two rows, column 'foo'\n",
    "\n",
    "print(data[:2].foo)\n",
    "\n",
    "print(data['foo'][:2])\n",
    "\n",
    "print(data['foo'].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "DataFrame information components can be access indiviually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print(data.columns)\n",
    "print(data.index)\n",
    "print(data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "<a id='DataFrameIndexers'></a>\n",
    "## `DataFrame` Indexers: loc & iloc\n",
    "\n",
    "Again, Pandas uses the ``loc``and ``iloc``*indexers* each relating to implicit or explcit indexing schemes. \n",
    "\n",
    "This makes indexing much less messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "area = pd.Series({'California': 423967, \n",
    "                  'Texas': 695662,\n",
    "                  'New York': 141297, \n",
    "                  'Florida': 170312,\n",
    "                  'Illinois': 149995})\n",
    "\n",
    "pop = pd.Series({'California': 38332521, \n",
    "                 'Texas': 26448193,\n",
    "                 'New York': 19651127, \n",
    "                 'Florida': 19552860,\n",
    "                 'Illinois': 12882135})\n",
    "\n",
    "US = pd.DataFrame({'area':area, 'pop':pop})\n",
    "US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always references the explicit index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US.loc['Illinois', 'pop'] # rows = Illinois, columns = pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US.loc[:'Florida', 'area'] # rows up to Florida, columns = area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US.loc[:'Illinois', :'pop'] # rows up to Illinois, columns up to pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## iloc\n",
    "Always references the implicit Python array-style index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "US.iloc[:3, :2]    # rows, columns    \n",
    "US.iloc[:3, [0,1]]\n",
    "US.iloc[2, 1]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any of the familiar NumPy-style data access patterns can be used within these indexers.\n",
    "\n",
    "Example\n",
    "<br>``loc`` indexer with masking and fancy indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US.loc[US.area > 200000, # indexes with area column > 200,000\n",
    "       ['pop', 'area']]  # columns pop and area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example\n",
    "<br>Mondify value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(US)\n",
    "US.iloc[2, 1] = 90 # row, column\n",
    "print(US)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Additional indexing conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Slicing by explicit index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "US['Florida':'Illinois']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Slicing by implicit index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "US[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Direct masking operations are interpreted row-wise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "US[US.area > 400000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='PerformingOperationsDataPandas'></a>\n",
    "# 4. Performing Operations on Data in Pandas\n",
    "\n",
    "<br> <a href='#VectorizedFunctions'>4.1 Vectorized Functions</a>\n",
    "<br> <a href='#Non-VectorizedFunctions'>4.2 Non-Vectorized Functions</a> \n",
    "<br> <a href='#ModifyingData'>4.3 Modifying Data</a> \n",
    "<br> <a href='#IndexAlignmentSeries'>4.4 Index Alignment in a `Series`</a> \n",
    "<br> <a href='#IndexAlignmentDataFrame'>4.4 Index alignment in a `DataFrame`</a> \n",
    "<br><a href='#OperationsBetweenDataFrameSeries'>4.5 Operations Between `DataFrame` and `Series`</a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy is useful for performing quick element-wise operations (e.g. basic arithmetic (addition, subtraction, multiplication...) , trigonometric functions, exponential and logarithmic functions etc). \n",
    "\n",
    "Pandas is designed to work with NumPy so any NumPy elementwise function (ufunc) will work on Pandas ``Series`` and ``DataFrame`` objects.\n",
    "\n",
    "Pandas builds on elementwise application by *preserving index and column labels* when implementing such functions. \n",
    "\n",
    "Idices are automatically *aligned* when passing the `Series`/`DataFrame` to the function.\n",
    "\n",
    "Operations between 1D ``Series`` structures and 2D ``DataFrame`` structures are similar to those in Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Main advantages:\n",
    "- keeping the context of data\n",
    "- combining data from different sources\n",
    "\n",
    "while error prone with NumPy, are automated when using Pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some examples to illustrate this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='VectorizedFunctions'></a>\n",
    "## 4.1 Vectorized Functions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "These functions automatically apply elementwise and can be used as with Numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example: `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42) # set random seed to give same random number each time\n",
    "\n",
    "ser = pd.Series(rng.randint(0, 10, 4)) # low = 0, high = 10, size = 4\n",
    "\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example: `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rng.randint(0, 10, (3, 4)),\n",
    "                  columns=['A', 'B', 'C', 'D'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The numpy function applies to all values in the `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The numpy function applies to all values in the `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin(df * np.pi / 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='SymbolicMathematics'></a>\n",
    "## 4.2 Non-Vectorized Functions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For functions that do not automatically apply elementwise we can use:\n",
    "- `Series.apply(function)` \n",
    "- `DataFrame.apply(function)` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Exmaple : Apply the `len` function to a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Series\n",
    "ser = pd.Series([[0,0,0],\n",
    "                 [0,0,0,0],\n",
    "                 [0,0,0,0,0],\n",
    "                 [0,0,0,0,0,0]])\n",
    "\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ser.apply(len) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example : Apply the `max` function to a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Data Frame\n",
    "df = pd.DataFrame(rng.randint(0, 10, (3, 4)),\n",
    "                  columns=['A', 'B', 'C', 'D'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.apply(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example : Apply the `max` function to a data frame or a Series wihtin a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'keys' : ['A', 'B', 'C', 'D'],\n",
    "                   'ser'  : ser,\n",
    "                   'vals' : list(range(4))},\n",
    "                  columns=['keys', 'ser', 'vals'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.apply(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ser.apply(len) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is a very good example of where `lambda` functions are used.\n",
    "\n",
    "Apply the function $x^2$ to each value, $x$ in the column `vals`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.vals.apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Initial values can be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.vals = df.vals.apply(lambda x: x**2)\n",
    "#df['vals']= df.vals.apply(lambda x: x**2)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "New columns (and rows) can be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['vals_orig'] = df.vals.apply(lambda x: x**(1/2))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ModifyingData'></a>\n",
    "## 4.3 Modifying Data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "It can be useful to modify indiividual values of a DataFrame.\n",
    "\n",
    "For exmaple, replacing/removing unwanted features of each item of changing the data type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing an Item / Part of an Item\n",
    "The `replace` method is not limited to string data but is particularly useful when dealing with strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_1 = {'Alaska': '$172',  \n",
    "         'Texas': '$695',\n",
    "         'California': '$423'\n",
    "        }\n",
    "\n",
    "\n",
    "tax_2 = {'California': '$3.8', \n",
    "         'Texas': '$2.6',\n",
    "         'New York': '$1.9'\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "US_tax = pd.DataFrame({'tax_1' : tax_1,\n",
    "                       'tax_2' : tax_2})\n",
    "\n",
    "US_tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "US_tax.replace('\\$', '', regex=True) # regex=True indicates string data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Changing Data Type\n",
    "Values can be cast as a different data type using  `astype`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_tax.replace('\\$', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sorting Items \n",
    "The `replace` method is not limited to string data but is particularly useful when dealing with strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_tax.sort_values(by = \"tax_1\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='IndexAlignmentSeries'></a>\n",
    "## 4.4 Index Alignment in a `Series`\n",
    "\n",
    "\n",
    "\n",
    "Consider combining two different data sources\n",
    "- the top three US states by *area*\n",
    "- the top three US states by *population*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.Series({'Alaska': 1723337, \n",
    "                  'Texas': 695662,\n",
    "                  'California': 423967\n",
    "                 }, \n",
    "                 name='area')\n",
    "\n",
    "\n",
    "population = pd.Series({'California': 38332521, \n",
    "                        'Texas': 26448193,\n",
    "                        'New York': 19651127\n",
    "                       }, \n",
    "                       name='population')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's use them to compute the population density:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population / area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The result array contains the *union* of indices of the two `DataFrame`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# union represented using set arithmetic\n",
    "area.index | population.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# | Union : ['Alaska', 'California', 'New York', 'Texas']\n",
    "# & Intersection : ['California', 'Texas']\n",
    "# – Difference : ['Alaska']\n",
    "# ^ Symmetric difference : ['Alaska', 'New York']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the result, any index missing from one of the `DataFrame`s is marked with ``NaN``, or \"Not a Number\".\n",
    "\n",
    "This is how Pandas marks missing data. \n",
    "\n",
    "This index matching is also applies to Python's built-in arithmetic operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.Series([2, 4, 6], index=[0, 1, 2])\n",
    "B = pd.Series([1, 3, 5], index=[1, 2, 3])\n",
    "A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If NaN values are undesirable in the result, the filler value can be modified by using an __object method__ for an operation. \n",
    "\n",
    "Addition : ``A + B``\n",
    "\n",
    "__Object method__ for addition :``A.add(B)`` <br>allows a *single* fill value to be specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.add(B, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='IndexAlignmentDataFrame'></a>\n",
    "## 4.4 Index alignment in a `DataFrame`\n",
    "\n",
    "\n",
    "\n",
    "Index alignment takes place for *both* columns and indices in ``DataFrame``s:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 x 2 `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1 = pd.DataFrame(rng.randint(0, 20, (2, 2)),\n",
    "                      columns=list('AB'))\n",
    "frame1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 x 3 `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frame2 = pd.DataFrame(rng.randint(0, 10, (3, 3)),\n",
    "                      columns=list('BAC'))\n",
    "frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Normal addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1 + frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example\n",
    "\n",
    "Fill with the mean of *all* values in ``frame1`` \n",
    "\n",
    "This is found by first stacking the rows of ``frame1``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame1.mean() # mean of each column\n",
    "\n",
    "fill = frame1.stack().mean() # stack stacks all columns on top of each other to form a single columns\n",
    "\n",
    "frame1.add(frame2, \n",
    "           fill_value=fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Python operators and their equivalent Pandas object methods:\n",
    "\n",
    "| Python Operator | Pandas Method(s)                      |\n",
    "|-----------------|---------------------------------------|\n",
    "| ``+``           | ``add()``                             |\n",
    "| ``-``           | ``sub()``, ``subtract()``             |\n",
    "| ``*``           | ``mul()``, ``multiply()``             |\n",
    "| ``/``           | ``truediv()``, ``div()``, ``divide()``|\n",
    "| ``//``          | ``floordiv()``                        |\n",
    "| ``%``           | ``mod()``                             |\n",
    "| ``**``          | ``pow()``                             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='OperationsBetweenDataFrameSeries'></a>\n",
    "## 4.5 Operations Between `DataFrame` and `Series`\n",
    "\n",
    "\n",
    "\n",
    "Index and column alignment is maintained.\n",
    "\n",
    "Operations between a ``DataFrame`` and a ``Series`` are similar to operations between a 2D and 1D NumPy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consider the following operation: \n",
    "\n",
    "Find the difference of a two-dimensional array and one of its rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(10, size=(3, 4))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A - A[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "According to NumPy's broadcasting rules (see [05_Algebra_SympyScipyNumpy__ClassMaterial](05_Algebra_SympyScipyNumpy__ClassMaterial.ipynb)):\n",
    "\n",
    "- subtraction between a 2D array and one of its rows is applied row-wise.\n",
    "\n",
    "- subtraction between a 2D array and one of its columns is applied column-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In Pandas, broadcast operations are *row-wise* when using normal operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(A, columns=list('QRST'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df - df.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df - df.iloc[0] # subtract row 0 (implicit indexing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To operate column-wise:\n",
    "- use __object methods__ mentioned earlier\n",
    "- specify the ``axis`` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.subtract(df['R']) # gives incorrect result, 'R' is not an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 0 = apply to each row, 1 = apply to each column\n",
    "df.subtract(df['R'], axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='DataCleaning'></a>\n",
    "# 5. Data Cleaning\n",
    "\n",
    "\n",
    "<br> <a href='#HandlingMissingData'>5.1 Handling Missing Data</a>\n",
    "<br> <a href='#DuplicateData'>5.2 Duplicate Data</a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='HandlingMissingData'></a>\n",
    "## Data Cleaning : Handling Missing Data\n",
    "\n",
    "Real-world data is rarely clean and homogeneous.\n",
    "\n",
    "In particular, many interesting datasets will have some amount of data missing.\n",
    "\n",
    "To make things even more complicated, different data sources may indicate missing data in different ways.\n",
    "\n",
    "Pandas has useful tools for handling missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Missing Data Conventions\n",
    "\n",
    "A number of schemes have been developed to indicate the presence of missing data in a table or DataFrame.\n",
    "Generally, they revolve around one of two strategies: \n",
    "- using a *mask* (a separate Boolean array to indicate missing values)\n",
    "- choosing a *sentinel value* that indicates a missing entry (e.g. `NaN`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Missing Data in Pandas\n",
    "\n",
    "Pandas uses two already-existing Python null values as sentinels for missing data:\n",
    "- floating-point ``NaN`` (*Not a Number*) value :  a special floating-point value recognized by all systems that use the standard floating-point representation.\n",
    "- Python ``None`` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print(1 + np.nan)\n",
    "print(0 *  np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "vals2 = np.array([1, np.nan, 3, 4])\n",
    "\n",
    "print(vals2.sum(), vals2.min(), vals2.max())\n",
    "\n",
    "print(np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "vals1 = np.array([1, None, 3, 4])\n",
    "print(vals1)\n",
    "vals1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### `NaN` and `None` in Pandas\n",
    "\n",
    "Pandas is built to handle ``NaN`` and ``None`` interchangeably, converting between them where appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# pandas automatucally converts int-->float, None-->NaN\n",
    "pd.Series([1, np.nan, 2, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='OperatingNullValues'></a>\n",
    "### Operating on Null Values\n",
    "\n",
    "\n",
    "\n",
    "There are several useful methods for detecting, removing, and replacing null values in Pandas data structures.\n",
    "They are:\n",
    "\n",
    "- ``isnull()``: Generate a boolean mask indicating missing values\n",
    "- ``notnull()``: Opposite of ``isnull()``\n",
    "- ``dropna()``: Return a filtered version of the data\n",
    "- ``fillna()``: Return a copy of the data with missing values filled or imputed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Detecting null values : ``isnull()`` and ``notnull()``\n",
    "Generate a boolean mask indicating missing/not missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([1, np.nan, 'hello', None])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Boolean masks can be used as a ``Series`` or ``DataFrame`` index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,      np.nan, 2],\n",
    "                   [2,      3,      5],\n",
    "                   [np.nan, 4,      6]])\n",
    "display(df.isnull())\n",
    "display(df[df.notnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dropping null values :  ``dropna()``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`Series` example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "``DataFrame`` example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,      np.nan, 2],\n",
    "                   [2,      3,      5],\n",
    "                   [np.nan, 4,      6]])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We cannot drop single values from a ``DataFrame``; we can only drop full rows or full columns.\n",
    "\n",
    "By default, ``dropna()`` will drop all rows in which *any* null value is present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Alternatively, you can drop NA values along a different axis; ``axis=1`` drops all columns containing a null value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In doing this we lose some of our data set. \n",
    "\n",
    "We can instead drop rows or columns with:\n",
    "- *all* NA values \n",
    "- a majority of NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Example DataFrame\n",
    "df[3] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Drop columns with all NaN values\n",
    "df.dropna(axis='columns', how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows with minimum 3 none-null values\n",
    "df.dropna(axis='rows', thresh=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the first and last row have been dropped, because they contain only two non-null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Filling null values : ``fillna()``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`Series` example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "display(data.fillna(0))  # fill NA entries with a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "display(data.fillna(method='ffill'))  # forward-fill to propagate the previous value forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "display(data.fillna(method='bfill'))  # back-fill to propagate the next values backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "``DataFrame`` example\n",
    "\n",
    "We can also specify an ``axis`` along which the fills take place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,      np.nan, 2],\n",
    "                   [2,      3,      5],\n",
    "                   [np.nan, 4,      6]])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# fill NaN with previous value in column\n",
    "df.fillna(method='ffill', axis=0) # forward-fill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fill NaN with previous value in row\n",
    "df.fillna(method='ffill', axis=1) # forward-fill "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can see the use of this if we consider the operation methods we used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(10, size=(3, 4)), columns=list('QRST'))\n",
    "display(df)\n",
    "\n",
    "halfcols = df.iloc[0, ::2]\n",
    "display(halfcols)\n",
    "\n",
    "df = df.subtract(halfcols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.fillna(method='ffill', axis=1) # fill columnwise with previous column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df.fillna(1) # fill NaN with single value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='DuplicateData'></a>\n",
    "## 5.2 Data Cleaning : Duplicate Data\n",
    "\n",
    " \n",
    "\n",
    "<br> <a href='#OperatingNullValues'>5.1 Operating on Null Values</a>\n",
    "<br> <a href='#PandasDataStructures'>2. Pandas Data Structures</a> \n",
    "<br> <a href='#DataIndexingSelection'>3. Data Indexing and Selection</a> \n",
    "<br> <a href='#PerformingOperationsDataPandas'>4. Performing Operations on Data in Pandas</a> \n",
    "<br><a href='#ReviewExercises'>5. Review Exercises</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Duplicates can be removed from the data set based on a particular column using `drop_duplicates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "header = ['Item 1', 'Item 2', 'Item 3', 'Item 4']\n",
    "df = pd.read_csv('sample_data/data_with_holes.csv', names=header)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates('Item 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By default, the first item of the duplicates is kept in the data set.\n",
    "\n",
    "Optionally, you can specify:\n",
    "- which value to keep (default keeps first)\n",
    "- to apply the change to the original data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates('Item 3',     # column to drop duplicates from\n",
    "                   keep='last',  # which instance to keepin data set\n",
    "                   inplace=True) # apply to original data set\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='CombiningDatasets'></a>\n",
    "# 6. Combining Datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the most interesting studies of data come from combining different data sources.\n",
    "\n",
    "These operations can involve：\n",
    "- straightforward concatenation of datasets\n",
    "- database-style joins and merges that handle any overlaps between the datasets.\n",
    "\n",
    "Please refer to the [08_Data__Supplementary](08_Data__Supplementary.ipynb)) for details of these operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='AggregationGrouping'></a>\n",
    "# 7. Summarising Data with Aggregation and Grouping\n",
    "\n",
    "<br> <a href='#SimpleAggregationPandas'>7.1 Simple Aggregation in Pandas</a>\n",
    "<br> <a href='#GroupBySplitApplyCombine'>7.2 `GroupBy`: `Split`, `Apply`, `Combine`</a> \n",
    "<br> <a href='#aggregatefiltertransformapply'>7.3 `aggregate`, `filter`, `transform`, `apply`</a> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Essential analysis of large data includes efficient summarization: e.g. computing aggregations like ``sum()``, ``mean()``, ``median()``, ``min()``, and ``max()``.\n",
    "\n",
    "In each case a single number gives insight into the nature of a potentially large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Planets Data\n",
    "\n",
    "Here we will use the Planets dataset, available via the [Seaborn package](http://seaborn.pydata.org/).\n",
    "\n",
    "It gives information on planets that astronomers have discovered around stars other than our sun <br>(known as *extrasolar planets* or *exoplanets* for short). \n",
    "\n",
    "It can be downloaded with a simple Seaborn command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "planets = sns.load_dataset('planets')\n",
    "\n",
    "planets.shape  # there are 1035 exoplanets in the data set and 6 fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='SimpleAggregationPandas'></a>\n",
    "## 7.1 Simple Aggregation in Pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with a one-dimensional NumPy array, for a Pandas ``Series`` the aggregates return a single value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42) # set a random seed\n",
    "ser = pd.Series(rng.rand(5))    # Series with 5 random values\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ser.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For a ``DataFrame``, by default the aggregates return results within each *column*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': rng.rand(5),\n",
    "                   'B': rng.rand(5)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By specifying the ``axis`` argument, you can instead aggregate within each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pandas ``Series`` and ``DataFrame``s include many common aggregates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table summarizes some other built-in Pandas aggregations:\n",
    "\n",
    "| Aggregation              | Description                     |\n",
    "|--------------------------|---------------------------------|\n",
    "| ``count()``              | Total number of items           |\n",
    "| ``first()``, ``last()``  | First and last item             |\n",
    "| ``mean()``, ``median()`` | Mean and median                 |\n",
    "| ``min()``, ``max()``     | Minimum and maximum             |\n",
    "| ``std()``, ``var()``     | Standard deviation and variance |\n",
    "| ``mad()``                | Mean absolute deviation         |\n",
    "| ``prod()``               | Product of all items            |\n",
    "| ``sum()``                | Sum of all items                |\n",
    "\n",
    "These are all methods of ``DataFrame`` and ``Series`` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "In addition, there is a convenience method ``describe()`` that computes several common aggregates for each column and returns the result.\n",
    "\n",
    "Let's use this on the Planets data, for now dropping rows with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.dropna().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This can be a useful way to begin understanding the overall properties of a dataset.\n",
    "\n",
    "\n",
    "We see in the ``year`` column that although exoplanets were discovered as far back as 1989, half of all known expolanets were not discovered until 2010 or after."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To go deeper into the data, however, simple aggregates are often not enough.\n",
    "\n",
    "The next level of data summarization is the ``groupby`` operation, which allows you to quickly and efficiently compute aggregates on subsets of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='GroupBySplitApplyCombine'></a>\n",
    "## 7.2 `GroupBy`: `Split`, `Apply`, `Combine`\n",
    "\n",
    "\n",
    "\n",
    "``groupby`` : aggregates conditionally on some label or index.\n",
    "\n",
    "- __split__ : breaking up and grouping a ``DataFrame`` depending on the value of the specified key.\n",
    "- __apply__ : computing some function, usually an aggregate, transformation, or filtering, within the individual groups.\n",
    "- __combine__ :merges the results of these operations into an output array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Split, apply, combine\n",
    "\n",
    "In the exmaple below, \"apply\" is a summation aggregation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/split_apply_combine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This could be achieved manually using a combination of the masking, aggregation, and merging commands we covered earlier.  \n",
    "\n",
    "``GroupBy`` can do this in a single step so the user need not think about *how* the computation is done, and can focus on the *operation as a whole*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Example__ : computation shown in this diagram.\n",
    "\n",
    "Creating the input ``DataFrame``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1': ['A', 'B', 'C', 'C', 'B', 'B', 'A'],\n",
    "                   'col2': [1, 2, 3, 4, 2, 5, 3]}, \n",
    "                  columns=['col1', 'col2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The most basic split-apply-combine operation can be computed with the ``groupby()`` method of ``DataFrame``s, passing the name of the desired key column.\n",
    "\n",
    "Notice that what is returned is not a set of ``DataFrame``s, but a ``DataFrameGroupBy`` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1': ['A', 'B', 'C', 'C', 'B', 'B', 'A'],\n",
    "                   'col2': [1, 2, 3, 4, 2, 5, 3]}, \n",
    "                  columns=['col1', 'col2'])\n",
    "\n",
    "df.groupby('col1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "To produce a result, apply an aggregate to this ``DataFrameGroupBy`` object.\n",
    "\n",
    "This will perform the appropriate apply/combine steps to produce the desired result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('col1').sum() # A DataFrame showing the sum of all items in groups A, B, C for each field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The ``sum()`` method is just an example.\n",
    "\n",
    "Apply any:\n",
    "- Pandas or NumPy aggregation function\n",
    "- ``DataFrame`` operation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `GroupBy` object\n",
    "\n",
    "The ``GroupBy`` object can be thought of as a collection of ``DataFrame``s.\n",
    "\n",
    "![](img/split_apply_combine.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Iteration over groups\n",
    "\n",
    "The ``GroupBy`` object supports direct iteration over the groups, returning each group as a ``Series`` or ``DataFrame``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (method, group) in planets.groupby('method'):\n",
    "    \n",
    "    # This print formatting leaves 30 spaces between printed item 0 and printed item 1\n",
    "    print(\"DataFrame name : {0:30s}, shape={1}\".format(method, group.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's also introduce some of the other functionality that can be used with the basic ``GroupBy`` operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Column indexing\n",
    "\n",
    "The ``GroupBy`` object supports column indexing in the same way as the ``DataFrame``, and returns a modified ``GroupBy`` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "planets.groupby('method') # choose a column name to group by e.g. method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.groupby('method')['orbital_period'] # choose a column name we are interested in e.g. orbital period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As with the ``GroupBy`` object, no computation is done until we call some aggregate on the object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Find the median orbital period of each measurement method\n",
    "planets.groupby('method')['orbital_period'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives an idea of the general scale of orbital periods (in days) that each method is sensitive to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='aggregatefiltertransformapply'></a>\n",
    "## 7.3 `aggregate`, `filter`, `transform`, `apply`\n",
    "\n",
    "\n",
    "\n",
    "In these examples we focused on aggregation for the combine operation, but there are more options available.\n",
    "\n",
    "![](img/split_apply_combine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "``GroupBy`` objects have the following methods:\n",
    "- ``aggregate()``\n",
    "- ``filter()``\n",
    "- ``transform()``\n",
    "- ``apply()`` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example ``DataFrame``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data1': range(6),\n",
    "                   'data2': rng.randint(0, 10, 6)},\n",
    "                   columns = ['key', 'data1', 'data2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Aggregation\n",
    "\n",
    "The ``aggregate()`` method extends the range of available aggregations beyond ``sum()``, ``median()`` etc.\n",
    "\n",
    "It can take a string/function/list and compute all the aggregates at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group items using column 'key' and find the min, median and max  of each column\n",
    "df.groupby('key').aggregate(['min', np.median, max]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Column names can be mapped to operations to be applied on that column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').aggregate({'data1': 'min',\n",
    "                             'data2': 'max'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Filtering\n",
    "\n",
    "Filter data based on the group properties.\n",
    "\n",
    "Example : keep all groups in which the standard deviation is larger than some critical value (e.g. 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)       # data frame\n",
    "display(df.groupby('key').std()) # standard deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def filter_func(x):\n",
    "    \"\"\" \n",
    "    Drop GROUPS from grouped DataFrame x with standard deviation of column 'data2' < 4\n",
    "    \"\"\"\n",
    "    return x['data2'].std() > 4\n",
    "\n",
    "\n",
    "display(df.groupby('key').filter(filter_func))\n",
    "\n",
    "display(df.groupby('key').filter(filter_func).groupby('key').std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Group A items have a standard deviation less than 4, so are dropped from the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The apply() method\n",
    "\n",
    "The ``apply()`` method lets you apply an arbitrary function to the group results.\n",
    "\n",
    "The function should have:\n",
    "- input``DataFrame``\n",
    "- return Pandas object (e.g., ``DataFrame``, ``Series``) or a scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example, here is an ``apply()`` that normalizes the first column to the sum (for that group) of the second:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_by_data2(x):\n",
    "    # x is a DataFrame of group values\n",
    "    x['data1'] /= x['data2'].sum()\n",
    "    return x\n",
    "\n",
    "display(df)\n",
    "display(df.groupby('key').apply(norm_by_data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "``apply()`` within a ``GroupBy`` is quite flexible: \n",
    "\n",
    "the only criterion is that the function takes a ``DataFrame`` and returns a Pandas object or scalar\n",
    "\n",
    "What else the function does is up to you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Specifying the split key\n",
    "\n",
    "In the simple examples presented before, we split the ``DataFrame`` on a single column name.\n",
    "\n",
    "This is just one of many options by which the groups can be defined.\n",
    "\n",
    "More are given in the supplementary material for you to explore independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grouping example\n",
    "\n",
    "Let's use grouping to count the number of  planets discovered during each decade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets['decade'] = 10 * (planets['year'] // 10) # new column : floor diivide by 10 then mutliply by ten\n",
    "\n",
    "planets.groupby('decade')['number'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's use grouping to count the number of  planets discovered __by each method__ during each decade:\n",
    "\n",
    "The returned values are stacked as a single column with each item a combination of decade and method using `groupby(['method', 'decade'])`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To display this more in a more readble way, use `unstack()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, replace all missing values with zeros using `fillna(0)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This shows the power of combining many of the operations we've discussed up to this point when looking at realistic datasets.\n",
    "\n",
    "We can see when and how planets have been discovered over the past several decades!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='StringData'></a>\n",
    "# 8. Working with `String` Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We have seen how tools like NumPy and Pandas generalize arithmetic operations.\n",
    "\n",
    "This allows us to easily and quickly perform the same operation on many array elements. \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([2, 3, 5, 7, 11, 13])\n",
    "\n",
    "x * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This *vectorization* of operations simplifies the syntax of operating on arrays of data.\n",
    "\n",
    "We no longer have to think about the size or shape of the array. \n",
    "\n",
    "We only need to consider what we want done.\n",
    "\n",
    "For arrays of strings, NumPy does not provide such simple access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['peter', 'Paul', 'MARY', 'gUIDO']\n",
    "\n",
    "# Lost comprehension to loop through each item in list.\n",
    "[s.capitalize() for s in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will break if there are any missing values.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['peter', 'Paul', None, 'MARY', 'gUIDO']\n",
    "[s.capitalize() for s in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pandas provides useful string operations for cleaning up real-world data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pandas includes features for:\n",
    "- vectorized string operations\n",
    "- handling missing data via the ``str`` attribute of Pandas Series and Index objects containing strings.\n",
    "\n",
    "So, for example, suppose we create a Pandas Series with this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.Series(data)\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now call a single method that will capitalize all the entries, while skipping over any missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using tab completion on this ``str`` attribute will list all the vectorized string methods available to Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tables of Pandas String Methods\n",
    "\n",
    "The examples in this section use the following series of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "monte = pd.Series(['Graham Chapman', 'John Cleese', 'Terry Gilliam',\n",
    "                   'Eric Idle', 'Terry Jones', 'Michael Palin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Methods similar to Python string methods\n",
    "Nearly all Python's built-in string methods have an equivalent Pandas vectorized string method. \n",
    "\n",
    "|             |                  |                  |                  |\n",
    "|-------------|------------------|------------------|------------------|\n",
    "|``len()``    | ``lower()``      | ``translate()``  | ``islower()``    | \n",
    "|``ljust()``  | ``upper()``      | ``startswith()`` | ``isupper()``    | \n",
    "|``rjust()``  | ``find()``       | ``endswith()``   | ``isnumeric()``  | \n",
    "|``center()`` | ``rfind()``      | ``isalnum()``    | ``isdecimal()``  | \n",
    "|``zfill()``  | ``index()``      | ``isalpha()``    | ``split()``      | \n",
    "|``strip()``  | ``rindex()``     | ``isdigit()``    | ``rsplit()``     | \n",
    "|``rstrip()`` | ``capitalize()`` | ``isspace()``    | ``partition()``  | \n",
    "|``lstrip()`` |  ``swapcase()``  |  ``istitle()``   | ``rpartition()`` |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Methods using regular expressions\n",
    "\n",
    "Methods that accept regular expressions (regex) to examine the content of each string element.\n",
    "\n",
    "These can be adapted with Python's built-in ``re`` module:\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| ``match()`` | Call ``re.match()`` on each element, returning a boolean. |\n",
    "| ``extract()`` | Call ``re.match()`` on each element, returning matched groups as strings.|\n",
    "| ``findall()`` | Call ``re.findall()`` on each element |\n",
    "| ``replace()`` | Replace occurrences of pattern with some other string|\n",
    "| ``contains()`` | Call ``re.search()`` on each element, returning a boolean |\n",
    "| ``count()`` | Count occurrences of pattern|\n",
    "| ``split()``   | Equivalent to ``str.split()``, but accepts regexps |\n",
    "| ``rsplit()`` | Equivalent to ``str.rsplit()``, but accepts regexps |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Miscellaneous methods\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| ``get()`` | Index each element |\n",
    "| ``slice()`` | Slice each element|\n",
    "| ``slice_replace()`` | Replace slice in each element with passed value|\n",
    "| ``cat()``      | Concatenate strings|\n",
    "| ``repeat()`` | Repeat values |\n",
    "| ``normalize()`` | Return Unicode form of string |\n",
    "| ``pad()`` | Add whitespace to left, right, or both sides of strings|\n",
    "| ``wrap()`` | Split long strings into lines with length less than a given width|\n",
    "| ``join()`` | Join strings in each element of the Series with passed separator|\n",
    "| ``get_dummies()`` | extract dummy variables as a dataframe |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Notice that these have various return values. Some, like ``lower()``, return a series of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# make all letters lower case\n",
    "monte.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Others return numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of each string\n",
    "monte.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or Boolean values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monte.str.startswith('T') # first letter is T\n",
    "\n",
    "monte.str.endswith('e') # last letter is e\n",
    "\n",
    "monte.str.contains('in') # contains the character sequence 'in' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Others return lists or other compound values for each element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "monte.str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And some can be used to modify the string data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_1 = {'Alaska': '$172K',  \n",
    "         'Texas': '$695K',\n",
    "         'California': '$423K'\n",
    "        }\n",
    "\n",
    "\n",
    "tax_2 = {'California': '$3.8M', \n",
    "         'Texas': '$2.6M',\n",
    "         'New York': '$1.9M'\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "US_tax = pd.DataFrame({'tax_1' : tax_1,\n",
    "                       'tax_2' : tax_2})\n",
    "\n",
    "US_tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "US_tax[US_tax.columns[:].str.replace('[\\$,]', '', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_tax.replace('[\\$,]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Vectorized slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# These two expressions are equivalent\n",
    "\n",
    "monte.str[0:3]\n",
    "\n",
    "monte.str.slice(0,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Indexing\n",
    "\n",
    "``df.str.get(i)`` and ``df.str[i]`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "monte.str.get(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example : \n",
    "\n",
    "``split()`` : splits a string into lists of words.\n",
    "\n",
    "``get()`` and ``slice()`` : let you access elements of a list e.g. arrays returned by ``split()``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example: extract the last name of each entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "monte.str.split() # use str.split() to split name strings into firstand last name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "monte.str.split().str.get(-1) # use str.get() to ge the last tem in each list (index[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Recipe Database\n",
    "\n",
    "Let's use these vectorized string operations to clean up messy, real-world data.\n",
    "\n",
    "This example uses a real open recipe database compiled from various sources on the Web.\n",
    "\n",
    "Goal : \n",
    "- parse the recipe data into ingredient list\n",
    "- quickly find a recipe based on some ingredients we have \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The database `db-recipes.json` is about 900 kB, and can be downloaded and unzipped by uncommenting the commands in the cell below and running the cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "A copy of the database can also be found in the `sample_data` folder of the `ILAS_PyEng2019` repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#!curl -O https://raw.githubusercontent.com/tabatkins/recipe-db/master/db-recipes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will import the data using the url..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create URL to JSON file (alternatively this can be a filepath)\n",
    "url = 'https://raw.githubusercontent.com/tabatkins/recipe-db/master/db-recipes.json'\n",
    "\n",
    "# Load the first sheet of the JSON file into a data frame\n",
    "# recipes = pd.read_json('sample_data/db-recipes.json') # use local copy\n",
    "recipes = pd.read_json(url) # use online version\n",
    "\n",
    "# View the first five rows\n",
    "recipes.head()\n",
    "\n",
    "# Transpose the DataFrame\n",
    "recipes = recipes.T\n",
    "\n",
    "# View the first five rows\n",
    "recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "recipes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there are nearly 500 recipes, and 18 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's take a look at one row, the first recipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There is a lot of information there, but much of it is in a very messy form, as is typical of data scraped from the Web.\n",
    "\n",
    "In particular, the ingredient list is in string format.\n",
    "\n",
    "Let's start by taking a closer look at the ingredients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.iloc[0]['ingredients']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see which recipe has the longest ingredient list.\n",
    "\n",
    "We can `apply` the function `len` to find the length of each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.ingredients.apply(len).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Find index of the recipe with the longest list of ingredients using `idxmax`.\n",
    "\n",
    "The index of the maximum row (`axis=0`) is returned. \n",
    "\n",
    "(If there is more than one item with the maximum value, the first is returned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.ingredients.map(len).idxmax(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This can be used as an index to find the name of the recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.name[recipes.ingredients.map(len).idxmax(axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how many recipes contain Pepper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join ingredients list to form a string\n",
    "recipes['ingredients'] = recipes['ingredients'].str.join(\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Search for the character string 'Pepper' using `str.contains()`\n",
    "\n",
    "We can search for multiple terms by seperating them by logical `or` operators : `'Pepper|pepper'`\n",
    "\n",
    "Count number of instances using `.sum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.ingredients.str.contains('Pepper|pepper').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Case insensitive search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # a library for regex handling\n",
    "\n",
    "recipes.ingredients.str.contains('pepper', flags=re.IGNORECASE).sum() # case insensitive search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Search for the character string 'Pepper' using `str.contains()`\n",
    "\n",
    "The result `seelction` is a boolean array so can be used as an index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = recipes.ingredients.str.contains('pepper', flags=re.IGNORECASE)\n",
    "\n",
    "# names of selected recipes (those containing pepper)\n",
    "recipes.name[selection].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A simple recipe recommender\n",
    "\n",
    "Goal : given a list of ingredients, find a recipe that uses all the ingredients.\n",
    "\n",
    "While conceptually straightforward, the task is complicated by the heterogeneity of the data: there is no easy operation, for example, to extract a clean list of ingredients from each row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "spice_list = ['salt', 'pepper', 'oregano', 'parsley']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Example 1 :__\n",
    "\n",
    "Find recipes containg *any* of the spices in the list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Join the list together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '|'\n",
    "\n",
    "s.join(spice_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Find recipes containing spices using `str.contains()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "spice_index = recipes.ingredients.str.contains(s) \n",
    "\n",
    "recipes.name[spice_index].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Example 2 :__\n",
    "\n",
    "Find recipes containg *all* of the spices in the list. \n",
    "\n",
    "This code shows what we want to achieve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spice_recipes = recipes[recipes.ingredients.str.contains('salt') &\n",
    "                        recipes.ingredients.str.contains('pepper') &\n",
    "                        recipes.ingredients.str.contains('oregano') &\n",
    "                        recipes.ingredients.str.contains('parsley')]\n",
    "\n",
    "spice_recipes.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This code is repetitive and error prone. \n",
    "\n",
    "We can improve it with a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we have narrowed down our recipe selection from nearly 500 to 2, we can  make a more informed decision about what we'd like to cook for dinner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='TimeSeries'></a>\n",
    "# 9. Working with Time Series\n",
    "\n",
    "<br> <a href='#IndexingTime'>9.1 Pandas Time Series: Indexing by Time</a>\n",
    "<br> <a href='#DataStructures'>9.2 Pandas Time Series : Data Structures</a> \n",
    "<br> <a href='#FrequenciesOffsets'>9.3 Frequencies and Offsets</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas was developed in the context of financial modeling, so it contains a fairly extensive set of tools for working with dates, times, and time-indexed data.\n",
    "\n",
    "- *Time stamps* : moments in time (e.g., July 4th, 2015 at 7:00am).\n",
    "- *Time intervals* and *periods* : length of time between a particular beginning and end point; for example, the year 2015. \n",
    "- *Time deltas* or *durations* : an exact length of time (e.g., a duration of 22.56 seconds).\n",
    "\n",
    "This is a broad overview of how you as a user should approach working with time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dates and Times in Python\n",
    "\n",
    "More generally, Python has a number of available representations of dates, times, deltas, and timespans.\n",
    "\n",
    "While the time series tools provided by Pandas tend to be the most useful for data science applications, it is helpful to see their relationship to other packages used in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Native Python dates and times: ``datetime`` and ``dateutil``\n",
    "\n",
    "Manually building a date using the ``datetime`` type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime(year=2015, month=7, day=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse dates from a variety of string formats with `dateutil`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "date = parser.parse(\"4th of July, 2015\")\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dates and times in pandas\n",
    "\n",
    "Pandas' ``Timestamp`` object, which combines ``datetime`` and ``dateutil`` with the efficient storage and vectorization. \n",
    "\n",
    "From a group of these ``Timestamp`` objects, Pandas can construct a ``DatetimeIndex`` that can be used to index data in a ``Series`` or ``DataFrame``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example : We can parse a flexibly formatted string date..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.to_datetime(\"4th of July, 2015\")\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Additionally, we can do NumPy-style vectorized operations directly on this same object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date + pd.to_timedelta(np.arange(12), 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date + pd.to_timedelta(np.arange(12), 'M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='IndexingTime'></a>\n",
    "## 9.1 Pandas Time Series: Indexing by Time\n",
    "\n",
    "\n",
    "\n",
    "Where the Pandas time series tools really become useful is when you begin to *index data by timestamps*.\n",
    "\n",
    "For example, we can construct a ``Series`` object that has time indexed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.DatetimeIndex(['2014-07-04', \n",
    "                          '2014-08-04',\n",
    "                          '2015-07-04', \n",
    "                          '2015-08-04'])\n",
    "data = pd.Series([0, 1, 2, 3], index=index)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we have this data in a ``Series``, we can make use of any of the ``Series`` indexing patterns we discussed in previous sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['2014-07-04':'2015-07-04']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are additional special date-only indexing operations, such as passing a year to obtain a slice of all data from that year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['2015']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='DataStructures'></a>\n",
    "## 9.2 Pandas Time Series : Data Structures\n",
    "\n",
    "\n",
    "\n",
    "- ``Timestamp`` \n",
    "- ``Period``\n",
    "- ``Timedelta``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime([pd.datetime(2015, 7, 3), \n",
    "                        '4th of July, 2015',\n",
    "                        '2015-Jul-6', \n",
    "                        '07-07-2015', \n",
    "                        '20150708'])\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Any ``DatetimeIndex`` can be converted to a ``PeriodIndex`` with the ``to_period()`` function with the addition of a frequency code; here we'll use ``'D'`` to indicate daily frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates.to_period('D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A ``TimedeltaIndex`` is created, for example, when a date is subtracted from another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates - dates[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regular sequences: ``pd.date_range()``\n",
    "\n",
    "Generating a regular date sequence.  \n",
    "\n",
    "We've seen that Python's ``range()`` and NumPy's ``np.arange()`` turn a startpoint, endpoint, and optional stepsize into a sequence.\n",
    "\n",
    "Similarly, ``pd.date_range()`` accepts a start date, an end date, and an optional frequency code to create a regular sequence of dates.\n",
    "\n",
    "By default, the frequency is one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range('2015-07-03', '2015-07-10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Alternatively, the date range can be specified with just a startpoint and a number of periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.date_range('2015-07-03', periods=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The spacing can be modified by altering the ``freq`` argument, which defaults to ``D``.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='FrequenciesOffsets'></a>\n",
    "## 9.3 Frequencies and Offsets\n",
    "\n",
    "\n",
    "\n",
    "The following table summarizes the main frequency codes available to set the frequency or offset of time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Code   | Description         | Code   | Description          |\n",
    "|--------|---------------------|--------|----------------------|\n",
    "| ``D``  | Calendar day        | ``B``  | Business day         |\n",
    "| ``W``  | Weekly              |        |                      |\n",
    "| ``M``  | Month end           | ``BM`` | Business month end   |\n",
    "| ``Q``  | Quarter end         | ``BQ`` | Business quarter end |\n",
    "| ``A``  | Year end            | ``BA`` | Business year end    |\n",
    "| ``H``  | Hours               | ``BH`` | Business hours       |\n",
    "| ``T``  | Minutes             |        |                      |\n",
    "| ``S``  | Seconds             |        |                      |\n",
    "| ``L``  | Milliseonds         |        |                      |\n",
    "| ``U``  | Microseconds        |        |                      |\n",
    "| ``N``  | nanoseconds         |        |                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The monthly, quarterly, and annual frequencies are all marked at the end of the specified period.\n",
    "By adding an ``S`` suffix to any of these, they instead will be marked at the beginning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "| Code    | Description            || Code    | Description            |\n",
    "|---------|------------------------||---------|------------------------|\n",
    "| ``MS``  | Month start            ||``BMS``  | Business month start   |\n",
    "| ``QS``  | Quarter start          ||``BQS``  | Business quarter start |\n",
    "| ``AS``  | Year start             ||``BAS``  | Business year start    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, here we will construct a range of hourly timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range('2015-07-03', periods=8, freq='H')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To create regular sequences of ``Period`` or ``Timedelta`` values, the very similar ``pd.period_range()`` and ``pd.timedelta_range()`` functions are useful.\n",
    "\n",
    "A period with increments increasing by month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.period_range('2015-07', periods=8, freq='M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And a sequence of durations increasing by an hour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.timedelta_range(0, periods=10, freq='H')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Visualizing Bicycle Counts\n",
    "\n",
    "Let's take a look the data comes from automated bicycle counter, installed on a bridge in 2012.\n",
    "\n",
    "The data contains the hourly count of bicycle traffic on the east and west side of a bridge to the centre of the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#!curl -o FremontBridge.csv https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use Pandas to read the CSV output into a ``DataFrame``.\n",
    "\n",
    "We must specify:\n",
    "- Date is the  index\n",
    "- we want these dates to be automatically parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file\n",
    "data = pd.read_csv('sample_data/FremontBridge.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For convenience, we'll further process this dataset by shortening the column names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns=['Total', 'East', 'West']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's take a look at the summary statistics for this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing the data\n",
    "\n",
    "We can gain some insight into the dataset by visualizing it.\n",
    "\n",
    "Let's start by plotting the raw data using pandas `plot` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot()\n",
    "plt.ylabel('Hourly Bicycle Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Resampling and converting frequencies\n",
    "\n",
    "One common need for time series data is resampling at a higher or lower frequency.\n",
    "\n",
    "This can be done using:\n",
    "- ``resample()`` (data aggregation method)\n",
    "- ``asfreq()`` (data selection method)\n",
    "\n",
    "\n",
    "Let's resample the bicycle count data by week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "weekly = data.resample('W').sum()     # data resampled weekly. all values summed (other options available)\n",
    "\n",
    "weekly.plot()                         # plt DataFrame\n",
    "\n",
    "plt.ylabel('Weekly bicycle count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This shows us some interesting seasonal trends: \n",
    "- people bicycle more in the summer than in the winter\n",
    "- within a particular season the bicycle use varies from week to week "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rolling Window Funcions\n",
    "\n",
    "__Rolling Function__ : Applies a funcion different subsets of the full data set.\n",
    "\n",
    "This rolling view makes available a number of aggregation operations by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Rolling Mean__ : Smooths data by creating a series of averages of different subsets of the full data set.\n",
    "\n",
    "We can use the ``pd.rolling_mean()`` function. \n",
    "\n",
    "Here we'll do a 30 day rolling mean of our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example: rolling mean with a window size of 30. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = data.resample('D').sum()                     # resampled to daily measurements, all values summed\n",
    "\n",
    "daily.rolling(50).sum().plot() # rolling window size of 30\n",
    "\n",
    "plt.ylabel('mean hourly count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Looking deeper into the data\n",
    "\n",
    "While these smoothed data views are useful to get an idea of the general trend in the data.\n",
    "\n",
    "Looking closer reveals interesting structures.\n",
    "\n",
    "We can look at the average traffic as a function of the time of day.\n",
    "\n",
    "We will use `GroupBy` where the index is given in the form `data.index.time`, `data.index.day`, `data.index.day`...etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "by_time = data.groupby(data.index.time).mean() # group by hour, mean value each hour\n",
    "\n",
    "hourly_ticks = 4 * 60 * 60 * np.arange(6)      # A list of 5 positions (gven in hours) at which ticks should be placed\n",
    "\n",
    "by_time.plot(xticks=hourly_ticks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The hourly traffic has a clear distribution.\n",
    "\n",
    "The peaks are around 8:00 in the morning and 5:00 in the evening.\n",
    "\n",
    "This is evidence of commuter traffic crossing the bridge.\n",
    "\n",
    "Further evidence : differences between: \n",
    "- west side of the bridge (generally used going into the city), which peaks more strongly in the morning\n",
    "- east side of the bridge (generally used coming out of the city), which peaks more strongly in the evening.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at how things change based on the day of the week. \n",
    "\n",
    "Again, we can do this with `groupby`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_weekday = data.groupby(data.index.dayofweek).mean() # group by weekday, mean value each weekday\n",
    "\n",
    "by_weekday.index = ['Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun'] # re-name the index\n",
    "\n",
    "weekday_ticks = np.arange(7)\n",
    "\n",
    "by_weekday.plot(xticks=weekday_ticks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Strong distinction between weekday and weekend totals.\n",
    "\n",
    "Around twice as many riders cross the bridge on Monday through Friday than on Saturday and Sunday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weekdays = data[data.index.weekday < 5]\n",
    "weekdays_by_time = weekdays.groupby(weekdays.index.time).mean() \n",
    "weekdays_by_time.plot()\n",
    "\n",
    "weekend = data[data.index.weekday >= 5]\n",
    "weekend_by_time = weekend.groupby(weekend.index.time).mean() \n",
    "weekend_by_time.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see:\n",
    "- a commute pattern during the work week\n",
    "- a recreational pattern during the weekends\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that we can use `matplotlib` to plot the data when we want to present it.\n",
    "\n",
    "Pandas' `plot` is useful for producing features quickly such as adding a legend and changing the style. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "weekdays_by_time.plot(kind=\"bar\")\n",
    "weekend_by_time.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(weekdays_by_time)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(weekend_by_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Saving a Data Frame\n",
    "<a id='SavingDataFrame'></a>\n",
    "The `to_csv`and `to_excel` methods can be used to save a `DataFrame`.\n",
    "\n",
    "These command can be used to save the data as almost *any* test-based filetype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "weekend_by_time.to_csv('sample_data/hourly_cycle_count_weekend.csv')\n",
    "weekend_by_time.to_csv('sample_data/hourly_cycle_count_weekend.txt')\n",
    "\n",
    "weekend_by_time.to_excel('sample_data/hourly_cycle_count_weekend.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The full list of optional function arguments can be found here: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html\n",
    "\n",
    "Five useful optional function arguments as examples:\n",
    "- `header` : new headers can be assigend as a list of strings OR the header can be omitted using\n",
    "- `float_format` : the number of decimal places\n",
    "- `sep`: delimter (default = \",\")\n",
    "- `mode` : the Python mode specifier (default = `w`)\n",
    " `header=False`.\n",
    "- `index` : write row names (default = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Review Exercises\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review Excercise: Restaurant Data\n",
    "\n",
    "Import the .tsv data set from https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv to a Pandas `DataFrame`.\n",
    "\n",
    "The data is a record of ordersplaced at restaurant 'Chipotle'.\n",
    "\n",
    "__(a)__ \n",
    "What was the most popular item (item ordered the most times)? <br>*Hint : Use `groupby`*\n",
    "\n",
    "__(b)__ \n",
    "What was the average sum of money spent on a single order? <br>*Hint : Convert prices to numerical data*\n",
    "\n",
    "__(c)__ \n",
    "For each bowl, burrito and tacos item (`Chicken Bowl` etc) there is a  `choice description`.  \n",
    "<br>Produce a table showing the number of times each `choice description` is selected for each bowl, burrito and tacos dish.\n",
    "<br>*Hint : USe `str.contains` then use `groupby` with __two__ arguments (see planets example)* \n",
    "<br>Your answer should resemble the table shown below:\n",
    "\n",
    "<img src=\"img/panda_table.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review Excercise: Time Series Data\n",
    "\n",
    "Import the multiTimeline.csv from the sample_data folder to a Pandas `DataFrame`.\n",
    "\n",
    "The data is a Google trends data of search keywords 'diet', 'gym' and 'finance' to see how they vary over time. \n",
    "\n",
    "Plot the data.\n",
    "*Hints : Use `skiprows` when importing the data to remove the first line.*\n",
    "\n",
    " \n",
    "\n",
    "__(a)__ \n",
    "Can you see a yearly repeating pattern in the data?<br>\n",
    "Plot the __average monthly instances of each search keyword__ for all years in the data set.<br>\n",
    "*Hints : Use `groupby`*<br>\n",
    "What conclusions could be drawn about this plot? \n",
    "\n",
    "__(b)__ \n",
    "Are there any noticable long-term trends over the period 2004-2017? \n",
    "<br>It's difficult to see because of the annual fluctuations.\n",
    "<br>Smooth the data to reveal any longer-term trends in the search keyword data.\n",
    "<br>*Hint : use rolling average or downsampling* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
